[
["prediction.html", "Section 7 Prediction", " Section 7 Prediction In this section, we move to our next social science goal Describe Explain, evaluate, and recommend \\(\\rightarrow\\) Causality Predict Discover Most of the tools we have been working on thus far have focused on first describing our data and then conducting tests through different types of comparisons and visualizations, in order to assess a deductive hypothesis, explaining the relationship between two variables. Now we turn to a different goal. Recall the difference between Correlation vs. Causality using our graphic showing the popularity of Duck Dynasty in different parts of the country. In 2016, researchers at the NY Times noticed that areas in the country where the television show Duck Dynasty was popular also tended to support Donald Trump at higher rates. For those used to working with the goal of explanation, shifting to prediction and classification may mean we need to shift what types of information we think is important. Correlation: Areas that watch Duck Dynasty are more likely to support Trump (degree to which two variables ``move together”) Causality: Watching Duck Dynasty (vs. not watching) causes you to support Trump. If we were interested in the goal of explaining voting decisions (what causes someone to vote a certain way?), we might not care if someone watches the show. However, if we were just interested in predicting vote share or voting decisions, a strong correlation could still be useful. Without spending a single dollar on surveying a community, we might have a general sense of their support for a candidate.\n"],
["prediction-overview.html", "7.1 Prediction Overview", " 7.1 Prediction Overview Our goal: Predict (estimate/guess) some unknown using information we have as accurately and precisely as possible Prediction could involve estimating a numeric outcome. Alternatively, prediction also involves classification– predicting a categorical outcome (e.g., prediction of who wins vs. who loses). Some political science examples of this might include Categorizing comments on social media as being toxic/nasty/uncivil Wired Detecting Fake news and misinformation PBS Forecasting election results Other examples Trying to detect hate speech online Predicting where or when an attack might occur Trying to classify a large amount of text into subject or topic categories for analysis What other types of things might we try to predict or classify in political science? "],
["process-of-prediction.html", "7.2 Process of Prediction", " 7.2 Process of Prediction Predict (estimate/guess) some unknown using information we have – and do so as accurately and precisely as possible. Choose an approach Using an observed (known) measure as a direct proxy to predict an outcome Using one or more observed (known) measures in a regression model to predict an outcome (Beyond the course) Using a statistical model to select the measures to use for predicting an outcome Assess accuracy and precision Prediction error: \\(Prediction - Truth\\) Bias: Average prediction error: \\(\\text{mean}(Prediction - Truth)\\) A prediction is `unbiased’ if the bias is zero (If the prediction is on average true) Root-mean squared error: \\(\\sqrt{\\text{mean}((Prediction - Truth)^2)}\\) Like `absolute’ error– the average magnitude of the prediction error the typical distance the prediction is from the truth Confusion Matrix A cross-tab of predictions you got correct vs. predictions you got wrong (misclassified) Gives you true positives and true negatives vs. false positives and false negatives Iterate to improve the prediction/classification Often, we repeat steps 1-3 until we are confident in your method for predicting. Eventually, after you have tested the approach and are satisfied with the accuracy, you may start applying it to new data for which you do not know the right answer. "]
]
